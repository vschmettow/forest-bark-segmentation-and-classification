# Forest Bark Analysis System

A complete machine learning system for automatically segmenting and classifying bark objects in forest images. The system identifies bark regions using state-of-the-art segmentation models (SAM2/SAM1) and classifies them using a trained YOLOv8 classifier.

## ğŸ¯ Project Overview

This project implements a **two-stage pipeline** for analyzing forest images:

1. **Segmentation Stage**: Uses Segment Anything Model (SAM2 or SAM1) to automatically detect and segment all objects in a forest image
2. **Classification Stage**: Uses a trained YOLOv8 classification model to identify each segmented object as **Picea**, **Pinus**, or **Other**

The system provides both web interfaces and command-line tools for easy use.

## ğŸ—ï¸ System Architecture

### High-Level Architecture

```
Forest Image
    â†“
[SAM2/SAM1 Segmentation] â†’ Finds all objects â†’ Generates masks
    â†“
[Object Extraction] â†’ Crops each masked region
    â†“
[YOLOv8 Classification] â†’ Classifies each object â†’ Picea/Pinus/Other
    â†“
[Visualization] â†’ Colored outlines + statistics
```

### Component Breakdown

#### 1. **Segmentation Module** (SAM2/SAM1)
- **Purpose**: Automatically finds and segments all objects in an image
- **Technology**: 
  - Primary: SAM2 (Segment Anything Model 2) - attempts to use first
  - Fallback: SAM1 (Segment Anything Model v1) - used if SAM2 unavailable
- **How it works**: 
  - Uses automatic mask generation to detect all objects
  - Filters out very small masks (< 1% of image area)
  - Generates segmentation masks for each detected object
- **Location**: Handled in `forest_bark_analyzer.py` and `forest_bark_analyzer_augmented.py`

#### 2. **Classification Module** (YOLOv8)
- **Purpose**: Classifies individual bark objects
- **Technology**: YOLOv8-s (small) classification model
- **Classes**: 
  - **Picea** (Spruce trees)
  - **Pinus** (Pine trees)
  - **Other** (if confidence < 95% threshold)
- **Model Variants**:
  - **Non-augmented**: Trained on original training data
  - **Augmented**: Trained on augmented (transformed) training data
- **Input**: 600x600 pixel images (automatically resized)
- **Confidence Threshold**: 95% (objects below threshold classified as "Other")
- **Location**: `data/models/yolov8_results/` (non-augmented) or `data/models/yolov8_results_augmented/` (augmented)

#### 3. **Integration Layer**
- **Web Applications**: Flask-based interfaces for easy interaction
- **Command-line Tools**: Scripts for batch processing and automation

## ğŸ“ Project Structure

```
Bark/
â”œâ”€â”€ apps/                          # Main applications
â”‚   â”œâ”€â”€ forest_bark_analyzer.py           # Full pipeline (segmentation + classification) - non-augmented model
â”‚   â”œâ”€â”€ forest_bark_analyzer_augmented.py # Full pipeline - augmented model
â”‚   â””â”€â”€ bark_classifier_web.py            # Simple classifier (classification only)
â”‚
â”œâ”€â”€ scripts/                       # Training and utility scripts
â”‚   â”œâ”€â”€ train_yolov8_classifier.py        # Train YOLOv8 classifier
â”‚   â”œâ”€â”€ create_augmented_dataset.py       # Create augmented training dataset
â”‚   â”œâ”€â”€ predict_yolov8_bark.py           # Command-line prediction
â”‚   â”œâ”€â”€ yolov8_dashboard_web.py          # Training dashboard
â”‚   â””â”€â”€ yolov8_dashboard_augmented.py    # Augmented training dashboard
â”‚
â”œâ”€â”€ tests/                         # Test files
â”‚   â”œâ”€â”€ test_sam2.py                      # SAM2 installation test
â”‚   â””â”€â”€ test_sam2_detailed.py             # Detailed SAM2 API test
â”‚
â”œâ”€â”€ docs/                          # Documentation
â”‚   â”œâ”€â”€ README.md                         # Legacy README (see root README.md)
â”‚   â”œâ”€â”€ README_YOLOv8.md                 # YOLOv8 detailed docs
â”‚   â”œâ”€â”€ FOREST_ANALYZER_README.md        # Forest analyzer guide
â”‚   â”œâ”€â”€ WEB_CLASSIFIER_README.md         # Web classifier guide
â”‚   â”œâ”€â”€ SAM2_INSTALLATION.md             # SAM2 installation guide
â”‚   â””â”€â”€ requirements.txt                  # Python dependencies
â”‚
â”œâ”€â”€ data/                          # Model files only
â”‚   â””â”€â”€ models/                           # Trained models
â”‚       â”œâ”€â”€ yolov8_results/              # Non-augmented model
â”‚       â””â”€â”€ yolov8_results_augmented/    # Augmented model
â”‚
â”œâ”€â”€ images/                        # All image data
â”‚   â”œâ”€â”€ training_data/                    # Training datasets
â”‚   â”‚   â”œâ”€â”€ training_data_augmented/      # Augmented dataset
â”‚   â”‚   â””â”€â”€ training_data_small_sample/   # Original dataset
â”‚   â”œâ”€â”€ test_images/                      # Test images
â”‚   â”œâ”€â”€ OriginalBark/                     # Original bark images
â”‚   â”œâ”€â”€ Picea-BarkNet-Part-1of4-modified/ # Modified Picea images
â”‚   â””â”€â”€ Pinus-Bark-KR-modified/          # Modified Pinus images
â”‚
â”œâ”€â”€ Archive/                       # Old/unused files
â”‚   â””â”€â”€ Preprocessing scripts/            # Old scripts and SAM weights
â”‚
â””â”€â”€ uploads/                       # Temporary upload directory (created by apps)
```

See `PROJECT_STRUCTURE.md` for detailed directory structure.

## âœ… What Has Been Done

### Phase 1: Data Collection & Preprocessing
- âœ… Collected bark image datasets for Picea and Pinus species
- âœ… Preprocessed images (segmentation, cropping, resizing)
- âœ… Created training/validation splits
- âœ… Prepared both original and modified image sets

### Phase 2: Model Training
- âœ… Trained YOLOv8 classification model on original data
  - Model: YOLOv8-s (small)
  - Image size: 600x600
  - Classes: Picea, Pinus
  - Confidence threshold: 95%
- âœ… Created augmented training dataset (rotations, flips, brightness adjustments, etc.)
- âœ… Trained second YOLOv8 model on augmented data for improved robustness

### Phase 3: Integration & Applications
- âœ… Integrated SAM1/SAM2 for automatic segmentation
- âœ… Built full pipeline combining segmentation + classification
- âœ… Created web interfaces:
  - Full analyzer (segmentation + classification)
  - Simple classifier (classification only)
- âœ… Implemented command-line prediction tools
- âœ… Added training dashboards for monitoring

### Phase 4: Optimization & Organization
- âœ… Implemented SAM2 support with fallback to SAM1
- âœ… Organized project into logical folder structure
- âœ… Created comprehensive documentation
- âœ… Set up proper path management for different model variants

## ğŸš€ Quick Start

### Prerequisites

1. **Python 3.10+**
2. **Install dependencies**:
   ```bash
   pip install -r docs/requirements.txt
   ```
3. **SAM Models** (choose one):
   - **SAM1** (recommended for simplicity): `pip install git+https://github.com/facebookresearch/segment-anything.git`
   - **SAM2** (optional, better performance): Clone repository and install (see `docs/SAM2_INSTALLATION.md`)
4. **Model Weights**: 
   - SAM weights: Place in `Archive/Preprocessing scripts/`
   - YOLOv8 models: Already in `data/models/`

### Running the Applications

#### Full Analyzer (Segmentation + Classification)

**Non-augmented model:**
```bash
cd apps
python3 forest_bark_analyzer.py
# Open http://localhost:5002
```

**Augmented model:**
```bash
cd apps
python3 forest_bark_analyzer_augmented.py
# Open http://localhost:5004
```

#### Simple Classifier (Classification Only)

```bash
cd apps
python3 bark_classifier_web.py
# Open http://localhost:5000
```

#### Command-Line Prediction

```bash
cd scripts
python3 predict_yolov8_bark.py --image path/to/image.jpg
```

### Training New Models

See the [Complete Training Guide](docs/TRAINING_GUIDE.md) for detailed instructions and model weight download links.

**Quick start:**
```bash
cd scripts
python3 train_yolov8_classifier.py --data_dir ../images/training_data/training_data_small_sample
```

## ğŸ”§ Technical Details

### Model Specifications

**YOLOv8 Classifier:**
- Architecture: YOLOv8-s (small)
- Input size: 600x600 pixels
- Output classes: Picea, Pinus, Other
- Confidence threshold: 95%
- Training: 60 epochs, batch size 4

**SAM Segmentation:**
- Primary: SAM2 (SAM2.1 Hiera Large) - 856MB checkpoint
- Fallback: SAM1 (ViT-H or ViT-B)
- Method: Automatic mask generation
- Filter: Masks < 1% image area removed

### Data Pipeline

1. **Input**: Forest/terrestrial image (JPEG/PNG, max 32MB)
2. **Segmentation**: SAM generates masks for all objects
3. **Filtering**: Small masks removed (< 1% of image)
4. **Extraction**: Each mask region cropped tightly
5. **Classification**: Each crop classified by YOLOv8
6. **Output**: Image with colored outlines + statistics

### Performance Considerations

- **First request**: Models load (~30-60 seconds)
- **Processing time**: Depends on image size and number of objects
  - Small images (< 2MP): 10-30 seconds
  - Large images (> 10MP): 1-5 minutes
- **GPU acceleration**: Significantly faster if available

## ğŸ“Š Current Status

### âœ… Completed Features
- Two-stage segmentation + classification pipeline
- SAM2 integration with SAM1 fallback
- Two trained model variants (original & augmented data)
- Web interfaces for easy use
- Command-line tools for batch processing
- Training dashboards
- Comprehensive documentation
- Organized project structure

### ğŸ¯ Model Variants

1. **Non-Augmented Model**: 
   - Trained on original training data
   - Location: `data/models/yolov8_results/`
   - Used by: `forest_bark_analyzer.py`

2. **Augmented Model**: 
   - Trained on augmented (transformed) data
   - Location: `data/models/yolov8_results_augmented/`
   - Used by: `forest_bark_analyzer_augmented.py`

### ğŸ“ Notes on SAM2 vs SAM1

- **SAM2** is preferred but requires more setup (repository clone + config files)
- **SAM1** is simpler (pip install) and works as reliable fallback
- Both use automatic mask generation (not text prompts)
- For text-prompt based segmentation, you'd need Grounding DINO + SAM2
- Current approach (automatic mask generation + YOLOv8 filtering) works well

## ğŸ“š Additional Documentation

- `PROJECT_STRUCTURE.md` - Detailed directory organization
- `docs/TRAINING_GUIDE.md` - **Complete training guide with model weight download links**
- `docs/FOREST_ANALYZER_README.md` - Full analyzer documentation
- `docs/WEB_CLASSIFIER_README.md` - Simple classifier documentation
- `docs/README_YOLOv8.md` - YOLOv8 training details
- `docs/SAM2_INSTALLATION.md` - SAM2 setup guide
- `docs/IMAGE_QUALITY_REQUIREMENTS.md` - Image quality guidelines

## ğŸ› ï¸ Development Notes

- All paths in scripts/apps are relative to their parent directories
- Run apps from `apps/` directory
- Run scripts from `scripts/` directory
- Models stored in `data/models/`
- Training data in `images/training_data/`

## ğŸ“„ License

This project is part of a university project (Projektarbeit).

## ğŸ™ Acknowledgments

- **SAM2/SAM1**: Facebook Research (Segment Anything Model)
- **YOLOv8**: Ultralytics
- **Bark Datasets**: Picea-BarkNet and Pinus-Bark-KR
# forest-bark-segmentation-and-classification
